{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2 -  Features Categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivos:\n",
    "\n",
    "Na segunda etapa, o objetivo é analisar os dados do case e estruturar uma Feature Engineering básica apenas com os dados categóricos existentes, também sem transformar ou combinar features ou mesmo adicionar informações externas. \n",
    "\n",
    "Ao final do desafio, será treinado um modelo de regressão linear com as features obtidas. Esse modelo será testado contra uma massa de teste, separada previamente.\n",
    "\n",
    "Também será agregada a feature engineering numérica em um segundo experimento de treino e avaliação, para comparar com a feat. eng. categórica sozinha. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup do Ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magic Functions do Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports de Libs Externas (padrão)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports de Libs Locais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset import load_california_housing_prices\n",
    "from pipeline import CategoricalFeaturesImputer, CategoricalToDummyFeaturesTransform, FeaturesChoiceTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = load_california_housing_prices()\n",
    "x_train = dataset[\"train\"][\"x\"]\n",
    "y_train = dataset[\"train\"][\"y\"]\n",
    "x_test = dataset[\"test\"][\"x\"]\n",
    "y_test = dataset[\"test\"][\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering c/ Features Categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features Categóricas são um pouco mais interessantes de tratar do que as numéricas, já que existem muitas maneiras de se transformar textos ou símbolos em valores numéricos. \n",
    "\n",
    "Vale lembrar que todo modelo de machine learning compreende o mundo através de valores numéricos, por serem modelos matemáticos de busca de solução ótima. Alguns frameworks atuais permitam que se coloquem valores simbólicos ou de texto marcados com a tag 'category' diretamente no dataset, mas por trás o proprio framework transforma esses dados em números."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise da Distribuição das Categorias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação da quantidade de dados em cada categoria\n",
    "\n",
    "É interessante verificar a quantidade de dados em cada categoria, pois categoriass mal representadas podem criar conceitos enviesados do modelo sobre o domínio. Por exemplo, em um dataset em que uma categoria só ocorra uma única vez e a variável dependente exatamente nesse elemento seja muito alta, um modelo treinado pode assumir que a presença dessa categoria já indique uma saída alta.\n",
    "\n",
    "A seguir, é verificada a distribuiçlão das categorias na massa de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[\"ocean_proximity\"].fillna(\" - NaN - \").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nem sempre é possível verificar a distribuição exata dos dados de produção, mas a massa de teste normalmente dá uma boa aproximação dela. A seguir é verificada a distribuição das categorias na massa de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[\"ocean_proximity\"].fillna(\" - NaN - \").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratamento de categorias pouco representativos:\n",
    "\n",
    "Pode-se observar que a categoria `ISLAND` tem uma representatividade mínima em todo o dataset, tornando essa categoria a única candidata à eliminação. Como já existem elementos com a categoria nula nesse dataset, a melhor estratégia é juntar a categoria `ISLAND` aos nulos e tratá-los (próxima seção)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Detecção e Tratamento de Nulos\n",
    "\n",
    "Como já foram identificados elementos em que a categoria é nula, é importante tratar esses elementos apropriadamente.\n",
    "\n",
    "Existem algumas estratégias para tratamento de nulos:\n",
    "\n",
    "- Criar uma categoria `NULL` e usar como um símbolo válido do sistema;\n",
    "- Criar modelos para inferir os valores a partir das outras features;\n",
    "- Imputar um valor referente à distribuição: a `moda` (valor com a maior frequência)\n",
    "\n",
    "Como existe a informação de que a variável categórica foi criada a partir da anotação manual do autor do dataset e que o mesmo utilizou as coordenadas `latitude` e `longitude`, a melhor estratégia é criar um `Imputer` que **busque a categoria do elemento usando as coordenadas geográfica**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "#### Tarefa (2.1) \n",
    "\n",
    "Completar a implementação do transformador de dados `CategoricalFeaturesImputer`. \n",
    "\n",
    "A classe está no arquivo `pipeline.py`.\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada a amostra dos dados de teste em que não há a informação categórica, mostrada a seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = x_test[x_test.ocean_proximity.isnull()]\n",
    "x_valid.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo testa o `imputer` em elementos da amostra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_categories = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\"]\n",
    "imputer = CategoricalFeaturesImputer(valid_categories).fit(x_train)\n",
    "imputer.transform(x_valid).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Transformação em Dummy Features\n",
    "\n",
    "A transformação em Dummy Features é a técnica em que os labels são formatados em dados categóricos consumíveis pelo modelo. O formato mais comum é usar uma representação em que cada label é uma nova feature binária onde o valor é **um** onde a feature é igual ao label e **zero** em todo o resto. \n",
    "\n",
    "Por exemplo, a transformação do vetor `[a, b, d, b, e, a, c]` seria da forma:\n",
    "\n",
    "| a | b | c | d | e |\n",
    "|---|---|---|---|---|\n",
    "| 1 | 0 | 0 | 0 | 0 |\n",
    "| 0 | 1 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 0 | 1 | 0 |\n",
    "| 0 | 1 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 0 | 0 | 1 |\n",
    "| 1 | 0 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 1 | 0 | 0 |\n",
    "\n",
    "Em modelos lineares existe uma regra de ouro que uma das classes deve permanecer como 'Base' para não haver uma feature linearmente dependente dentro do dataset. Alguns modelos tratam esse problema internamente, mas ainda assim é uma boa prática a ser seguida.\n",
    "\n",
    "Como é uma etapa de pré-processamento, essa transformação também deve ser feita como uma Feature Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "#### Tarefa (2.2) \n",
    "\n",
    "Completar a implementação do transformador de dados `CategoricalToDummyFeaturesTransform`. \n",
    "\n",
    "A classe está no arquivo `pipeline.py`.\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar o novo transformador de dados, serão contabilizadas apenas as categorias `INLAND`, `NEAR OCEAN` e `NEAR BAY` na amostra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\"]\n",
    "\n",
    "CategoricalToDummyFeaturesTransform(categories).transform(x_train).iloc[:10, -6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e Avaliação de um Modelo Linear\n",
    "\n",
    "Continuando o treinamento do notebook anterior, serão feitas dois sets de treinamento e avaliação:\n",
    "\n",
    "1. Apenas com a Feature Engineering Categórica;\n",
    "2. Agregando as Feature Engineerings Numérica e Categórica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reload das massas de Treino e de Teste\n",
    "\n",
    "As massas de dados de Treino e de Teste serão carregadas novamente para que seja aplicado o pipeline de pré-processamento em ambos desde o princípio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = load_california_housing_prices()\n",
    "x_train = dataset[\"train\"][\"x\"]\n",
    "y_train = dataset[\"train\"][\"y\"]\n",
    "x_test = dataset[\"test\"][\"x\"]\n",
    "y_test = dataset[\"test\"][\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deve-se remover os outliers da massa de treino usando a função construída para isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_index = joblib.load(os.path.join(\"pipelines\", \"keep_index.pkl\"))\n",
    "x_train = x_train[keep_index]\n",
    "y_train = y_train[keep_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pipeline contendo apenas a Feature Engineering Categórica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Pipeline de Pré-Processamento\n",
    "\n",
    "Apenas as etapas da Feature Engineering Categórica devem estar aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_feat_eng_pipeline = Pipeline([\n",
    "    (\"categorical_imputer\",      CategoricalFeaturesImputer(categories)),\n",
    "    (\"dummy_category_transform\", CategoricalToDummyFeaturesTransform(categories)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse pipeline será treinado e salvo para ser usado nos próximos notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat_eng_pipeline.fit(x_train)\n",
    "joblib.dump(\n",
    "    value=cat_feat_eng_pipeline.fit(x_train),\n",
    "    filename=os.path.join(\"pipelines\", \"categorical_feat_eng.pkl\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Pipeline Completo\n",
    "\n",
    "Todas as etapas de pré-processamento devem estar incluídas nesse pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosen_features = [f\"ocean_proximity: {c}\" for c in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"categorical_feat_eng\",  cat_feat_eng_pipeline),\n",
    "    (\"features_choice\",       FeaturesChoiceTransform(chosen_features)),\n",
    "    (\"zscore\",                StandardScaler()),\n",
    "    (\"predictor\",             ElasticNet()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Treinar e avaliar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação do modelo nas massas de **treino** e de **teste**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = y_train\n",
    "y_pred = pipeline.predict(x_train)\n",
    "mse_tr = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "r2_tr = r2_score(y_true=y_true, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = y_test\n",
    "y_pred = pipeline.predict(x_test)\n",
    "mse_te = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "r2_te = r2_score(y_true=y_true, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    index=[\"train\", \"test\"],\n",
    "    columns=[\"MSE\", \"R^2\"],\n",
    "    data=[\n",
    "        [mse_tr, r2_tr],\n",
    "        [mse_te, r2_te]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pipeline contendo as Feature Engineerings Numérica & Categórica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Pipeline de Pré-Processamento\n",
    "\n",
    "Todas as etapas de pré-processamento devem estar incluídas nesse pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    \"longitude\", \"latitude\", \n",
    "    \"housing_median_age\", \n",
    "    \"total_rooms\", \"total_bedrooms\",  \n",
    "    \"population\", \"households\", \"median_income\"\n",
    "]\n",
    "\n",
    "log_transform_features = [\n",
    "    \"total_rooms\", \"total_bedrooms\", \n",
    "    \"population\", \"households\", \n",
    "    \"median_income\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosen_features = (numerical_features +\n",
    "                   [f\"log_of_{c}\" for c in log_transform_features] + \n",
    "                   [f\"ocean_proximity: {c}\" for c in categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_feat_eng_pipeline = joblib.load(os.path.join(\"pipelines\", \"numerical_feat_eng.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"numerical_feat_eng\",    num_feat_eng_pipeline),\n",
    "    (\"categorical_feat_eng\",  cat_feat_eng_pipeline),\n",
    "    (\"features_choice\",       FeaturesChoiceTransform(chosen_features)),\n",
    "    (\"zscore\",                StandardScaler()),\n",
    "    (\"predictor\",             ElasticNet()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Treinar e avaliar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação do modelo nas massas de **treino** e de **teste**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = y_train\n",
    "y_pred = pipeline.predict(x_train)\n",
    "mse_tr = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "r2_tr = r2_score(y_true=y_true, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = y_test\n",
    "y_pred = pipeline.predict(x_test)\n",
    "mse_te = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "r2_te = r2_score(y_true=y_true, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    index=[\"train\", \"test\"],\n",
    "    columns=[\"MSE\", \"R^2\"],\n",
    "    data=[\n",
    "        [mse_tr, r2_tr],\n",
    "        [mse_te, r2_te]\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
