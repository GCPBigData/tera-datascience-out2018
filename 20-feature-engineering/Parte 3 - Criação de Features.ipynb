{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3 -  Criação de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos:\n",
    "\n",
    "Na terceira etapa do desafio, o que será explorado será exatamente a combinação de features e o uso de informações externas.\n",
    "\n",
    "No final dessa etapa, será treinado um modelo agregando todo o pipeline desenvolvido até o momento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup do Ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magic Functions do Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports de Libs Externas (padrão)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports de Libs Locais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset import load_california_housing_prices\n",
    "from pipeline import (\n",
    "    ManuallyCraftedFeaturesTransform, PolynomialFeaturesTransform, \n",
    "    PointsOfInterestFeaturesTransform, FeaturesChoiceTransform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = load_california_housing_prices()\n",
    "x_train = dataset[\"train\"][\"x\"]\n",
    "y_train = dataset[\"train\"][\"y\"]\n",
    "x_test = dataset[\"test\"][\"x\"]\n",
    "y_test = dataset[\"test\"][\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a Feature Engineering apresentada nessa etapa deve ser feita sobre as features já tratadas, as soluções numérica e categórica serão aplicadas aos dados originais. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_pipeline = Pipeline([\n",
    "    (\"numerical_feat_eng\",   joblib.load(os.path.join(\"pipelines\", \"numerical_feat_eng.pkl\"))),\n",
    "    (\"categorical_feat_eng\", joblib.load(os.path.join(\"pipelines\", \"categorical_feat_eng.pkl\")))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = prev_pipeline.transform(x_train)\n",
    "x_test = prev_pipeline.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Engineering c/ Combinação de Features e Features Externas\n",
    "\n",
    "Para enriquecer ainda mais os modelos, pode-se combinar as features existentes entre si e com features extraídas de fontes externas de conhecimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinação Manual de Features\n",
    "\n",
    "É uma prática comum agrupar manualmente features por assunto ou grupos de conhecimento, principalmente quando se tem um bom conhecimento do domínio de aplicação. \n",
    "\n",
    "Algumas features numéricas nesse dataset são bem relacionadas entre si, sendo imediato pensar em combiná-las. Para manter o padrão no pré-processamento, isso será feito em uma classe de Feature Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "#### Tarefa (3.1) \n",
    "\n",
    "Completar a implementação do transformador de dados `ManuallyCraftedFeaturesTransform`. \n",
    "\n",
    "A classe está no arquivo `pipeline.py`.\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando as novas features criadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ManuallyCraftedFeaturesTransform().transform(x_train).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinação Polinomial de Features\n",
    "\n",
    "Uma outra técnica muito utilizada em feature engineering é criar novas features a partir da combinação polinomial de features antigas. Dessa forma, uma solução linear pode ser extendida para uma solução não linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "#### Tarefa (3.2) \n",
    "\n",
    "Completar a implementação do transformador de dados `PolynomialFeaturesTransform`. \n",
    "\n",
    "A classe está no arquivo `pipeline.py`.\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir pode-se observar um teste com uma amostra das features que compõem o dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"longitude\", \"latitude\", \n",
    "    \"households\", \"total_bedrooms\", \"total_rooms\"    \n",
    "]\n",
    "\n",
    "PolynomialFeaturesTransform(features, 3).fit_transform(x_train).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados Externos: Pontos de Interesse\n",
    "\n",
    "Uma das técnicas que mais trazem informação para o modelo é a inclusão de dados externos. \n",
    "\n",
    "Para essa seção, deve-se escolher alguns pontos de interesse da Califórina e arredores para calcular a distância euclidiana da Latitude/Longitude do data point a esses pontos de interesse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "#### Tarefa (3.3) \n",
    "\n",
    "Completar a implementação do transformador de dados `PointsOfInterestFeaturesTransform`. \n",
    "\n",
    "A classe está no arquivo `pipeline.py`.\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir o novo transformador pode ser visto em ação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PointsOfInterestFeaturesTransform().fit_transform(x_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e Avaliação de um Modelo Linear\n",
    "\n",
    "Serão utilizadas todas as soluções construídas de Feature Engineering para extrair ao máximo o potencial do modelo linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reload das massas de Treino e de Teste\n",
    "\n",
    "As massas de dados de Treino e de Teste serão carregadas novamente para que seja aplicado o pipeline de pré-processamento em ambos desde o princípio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = load_california_housing_prices()\n",
    "x_train = dataset[\"train\"][\"x\"]\n",
    "y_train = dataset[\"train\"][\"y\"]\n",
    "x_test = dataset[\"test\"][\"x\"]\n",
    "y_test = dataset[\"test\"][\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deve-se remover os outliers da massa de treino usando a função construída para isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_index = joblib.load(os.path.join(\"pipelines\", \"keep_index.pkl\"))\n",
    "x_train = x_train[keep_index]\n",
    "y_train = y_train[keep_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pipeline contendo todas as Feature Engineerings construídas até o momento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Pipeline de Pré-Processamento\n",
    "\n",
    "Todas as etapas de pré-processamento devem estar incluídas nesse pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    \"longitude\", \"latitude\", \n",
    "    \"housing_median_age\", \n",
    "    \"total_rooms\", \"total_bedrooms\",  \n",
    "    \"population\", \"households\", \"median_income\"\n",
    "]\n",
    "\n",
    "log_transform_features = [\n",
    "    \"total_rooms\", \"total_bedrooms\", \n",
    "    \"population\", \"households\", \n",
    "    \"median_income\"\n",
    "]\n",
    "\n",
    "categories = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\"]\n",
    "\n",
    "poly_features = [\n",
    "    \"longitude\", \"latitude\", \n",
    "     \"housing_median_age\", \"total_rooms\", \"total_bedrooms\",\n",
    "     \"population\", \"households\", \"median_income\",\n",
    "     \"log_of_total_rooms\", \"log_of_total_bedrooms\", \"log_of_population\", \n",
    "     \"log_of_households\", \"log_of_median_income\"\n",
    "]\n",
    "poly_degree = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosen_features = (numerical_features +\n",
    "                   [f\"log_of_{c}\" for c in log_transform_features] + \n",
    "                   [f\"ocean_proximity: {c}\" for c in categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"previous_pipeline\",          prev_pipeline),\n",
    "    (\"features_choice\",            FeaturesChoiceTransform(chosen_features)),\n",
    "    (\"manually_crafted_transform\", ManuallyCraftedFeaturesTransform()),\n",
    "    (\"polynomial_feats_transform\", PolynomialFeaturesTransform(poly_features, poly_degree)),\n",
    "    (\"ext_poi_feats_transform\",    PointsOfInterestFeaturesTransform()),\n",
    "    (\"zscore\",                     StandardScaler()),\n",
    "    (\"predictor\",                  ElasticNet()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Treinar e avaliar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação do modelo nas massas de **treino** e de **teste**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = y_train\n",
    "y_pred = pipeline.predict(x_train)\n",
    "mse_tr = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "r2_tr = r2_score(y_true=y_true, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = y_test\n",
    "y_pred = pipeline.predict(x_test)\n",
    "mse_te = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "r2_te = r2_score(y_true=y_true, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    index=[\"train\", \"test\"],\n",
    "    columns=[\"MSE\", \"R^2\"],\n",
    "    data=[\n",
    "        [mse_tr, r2_tr],\n",
    "        [mse_te, r2_te]\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
